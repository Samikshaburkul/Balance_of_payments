mutate(row_num = row_number()) %>%
ungroup()
# For the first indicator of each country, keep the country name, for others replace with ""
expanded_data$Country[expanded_data$row_num != 1] <- ""
# Select only the Country and Indicator columns
final_data <- expanded_data %>%
select(Country, Indicator)
# Write the final data to an Excel file
write_xlsx(final_data, "/Users/sai_avinash/Desktop/final_data.xlsx")
# write to excel file
#write_xlsx(aggregated_data, "/Users/sai_avinash/Desktop/aggregated_data.xlsx")
# load the packages into R
library(dplyr)
# Create a new data frame with each country-indicator combination on a separate row
expanded_data <- bops_data %>%
select(Country, Indicator) %>%
distinct()
# Add a dummy column to help with ordering
expanded_data <- expanded_data %>%
group_by(Country) %>%
mutate(row_num = row_number()) %>%
ungroup()
# For all rows except the first indicator of each country, replace the country name with an empty string
expanded_data$Country[expanded_data$row_num != 1] <- ""
# Select only the Country and Indicator columns
final_data <- expanded_data %>%
select(Country, Indicator)
# Write the final data to an Excel file
write_xlsx(final_data, "/Users/sai_avinash/Desktop/final_data2.xlsx")
# Write the final data to an Excel file
#write_xlsx(final_data, "/Users/sai_avinash/Desktop/final_data.xlsx")
# write to excel file
#write_xlsx(aggregated_data, "/Users/sai_avinash/Desktop/aggregated_data.xlsx")
# load the packages into R
library(dplyr)
library(tidyr)
# Group by Country and create a list column of all indicators for each country
aggregated_data <- bops_data %>%
group_by(Country) %>%
summarise(Indicator = list(unique(Indicator))) %>%
ungroup()
# Expand the list column to create multiple rows for each indicator
expanded_data <- aggregated_data %>%
unnest(cols = c(Indicator))
# Replace repeated country names with NA after the first occurrence
expanded_data$Country <- with(expanded_data, replace(Country, duplicated(Country), NA))
# Write the data to an Excel file
write_xlsx(expanded_data, "/Users/sai_avinash/Desktop/expanded_data.xlsx")
# Write the final data to an Excel file
#write_xlsx(final_data, "/Users/sai_avinash/Desktop/final_data2.xlsx")
# Write the final data to an Excel file
#write_xlsx(final_data, "/Users/sai_avinash/Desktop/final_data.xlsx")
# write to excel file
#write_xlsx(aggregated_data, "/Users/sai_avinash/Desktop/aggregated_data.xlsx")
knitr::opts_chunk$set(echo = TRUE)
# Common Indicators for all the countries
library(dplyr)
# Count the number of unique countries for each indicator
indicator_counts <- bops_data %>%
group_by(Indicator) %>%
summarise(num_countries = n_distinct(Country)) %>%
ungroup()
# Total number of unique countries in the dataset
total_countries <- n_distinct(bops_data$Country)
# Filter indicators that are common for every country
common_indicators <- indicator_counts %>%
filter(num_countries == total_countries) %>%
pull(Indicator)
# Print the common indicators
print(common_indicators)
knitr::opts_chunk$set(echo = TRUE)
# Change the data types
bops_data$CountryCode <- as.factor(bops_data$CountryCode)
# Years to be changed as numeric
years_columns <- c("2015", "2016", "2017", "2018", "2019", "2020")
bops_data[years_columns] <- lapply(bops_data[years_columns], as.numeric)
# Store the new data set as a CSV file
write.csv(bops_data, "new_BOPS.csv")
# Change the data types
bops_data$CountryCode <- as.factor(bops_data$CountryCode)
# Years to be changed as numeric
years_columns <- c("2015", "2016", "2017", "2018", "2019", "2020")
bops_data[years_columns] <- lapply(bops_data[years_columns], as.numeric)
bops_data
# Store the new data set as a CSV file
#write.csv(bops_data, "new_BOPS.csv")
# Change the data types
bops_data$CountryCode <- as.factor(bops_data$CountryCode)
# Years to be changed as numeric
years_columns <- c("2015", "2016", "2017", "2018", "2019", "2020")
bops_data[years_columns] <- lapply(bops_data[years_columns], as.numeric)
bops_data[S.No] <- NULL
# Change the data types
bops_data$CountryCode <- as.factor(bops_data$CountryCode)
# Years to be changed as numeric
years_columns <- c("2015", "2016", "2017", "2018", "2019", "2020")
bops_data[years_columns] <- lapply(bops_data[years_columns], as.numeric)
bops_data['S.No'] <- NULL
bops_data
# Store the new data set as a CSV file
#write.csv(bops_data, "new_BOPS.csv")
# Change the data types
bops_data$CountryCode <- as.factor(bops_data$CountryCode)
# Years to be changed as numeric
years_columns <- c("2015", "2016", "2017", "2018", "2019", "2020")
bops_data[years_columns] <- lapply(bops_data[years_columns], as.numeric)
bops_data['S.No'] <- NULL
bops_data
# Store the new data set as a CSV file
write.csv(bops_data, "new_BOPS.csv")
knitr::opts_chunk$set(echo = TRUE)
summary(df_50)
df_50 <- subset(df, Country %in% c('Lebanon','Lesotho, Kingdom of','Liberia','Libya','Lithuania','Luxembourg','Madagascar, Rep. of','Malawi','Malaysia','Maldives','Mali','Malta','Marshall Islands, Rep. of the','Mauritania, Islamic Rep. of','Mauritius','Mexico','Moldova, Rep. of','Mongolia','Montenegro','Montserrat', 'Morocco','Mozambique, Rep. of','Myanmar','Namibia','Nauru, Rep. of','Nepal','Netherlands, The','New Caledonia','New Zealand','Nicaragua','Niger','Nigeria','North Macedonia, Republic of','Norway','Oman','Pakistan','Palau, Rep. of','Panama','Papua New Guinea','Paraguay','Peru','Philippines','Poland, Rep. of','Portugal','Qatar','Romania','Russian Federation','Rwanda','Samoa','São Tomé and Príncipe, Dem. Rep. of'))
df <- read.csv('BOP_09-13-2023 17-28-15-94_timeSeries.csv',header = TRUE)
c <-nrow(df)
print(c)
str(df)
df <- subset(df, Indicator %in% c('Capital Account, Capital Transfers, Credit, US Dollars','Capital Account, Capital Transfers, Net, US Dollars','Capital Account, Total, Credit, US Dollars','Capital Account, Total, Debit, US Dollars','Capital Account, Total, Net, US Dollars','Current Account, Goods and Services, Credit, US Dollars','Current Account, Goods and Services, Debit, US Dollars','Current Account, Goods and Services, Services, Transport, Credit, US Dollars','Current Account, Goods and Services, Services, Transport, Debit, US Dollars','Current Account, Primary Income, Investment Income, Direct Investment, Credit, US Dollars','Current Account, Primary Income, Investment Income, Direct Investment, Debit, US Dollars','Supplementary Items, Reserve Assets (with Fund Record), US Dollars','Supplementary Items, Reserve Position in the Fund (with Fund Record), US Dollars','Financial Account, Net Lending (+) / Net Borrowing (-) (Balance from Financial Account), Direct Investment, Net Acquisition of Financial Assets, Equity and Investment Fund Shares, Equity Other Than Reinvestment of Earnings, US Dollars','Financial Account, Net Lending (+) / Net Borrowing (-) (Balance from Financial Account), Direct Investment, Net Acquisition of Financial Assets, Equity and Investment Fund Shares, US Dollars','Financial Account, Net Lending (+) / Net Borrowing (-) (Balance from Financial Account), Direct Investment, Net Acquisition of Financial Assets, US Dollars','Financial Account, Net Lending (+) / Net Borrowing (-) (Balance from Financial Account), Direct Investment, Net Incurrence of Liabilities, Debt Instruments, US Dollars','Financial Account, Other Investment, Loans, Net Acquisition of Financial Assets, US Dollars','Financial Account, Other Investment, Loans, Net Incurrence of Liabilities, General Government, Other Long-term, US Dollars','Financial Account, Other Investment, Loans, Net Incurrence of Liabilities, General Government, US Dollars','Financial Account, Other Investment, Loans, Net Incurrence of Liabilities, Other Sectors, Long-term, US Dollars','Financial Account, Other Investment, Loans, Net Incurrence of Liabilities, Other Sectors, US Dollars','Financial Account, Other Investment, Loans, Net Incurrence of Liabilities, US Dollars','Financial Account, Other Investment, Loans, US Dollars','Financial Account, Portfolio Investment, Net Acquisition of Financial Assets, Debt Securities, US Dollars','Financial Account, Portfolio Investment, Net Acquisition of Financial Assets, Equity and Investment Fund Shares, US Dollars','Financial Account, Portfolio Investment, Net Acquisition of Financial Assets, US Dollars','Financial Account, Portfolio Investment, Net Incurrence of Liabilities, Debt Securities, US Dollars','Net Lending (+) / Net Borrowing (-) (Balance from Current and Capital Account), US Dollars','Supplementary Items, Total Current + Capital Account, US Dollars','Supplementary Items, Portfolio Investment, Net Incurrence of Liabilities (Excluding Exceptional Financing), US Dollars'))
summary(df)
df_50 <- subset(df, Country %in% c('Lebanon','Lesotho, Kingdom of','Liberia','Libya','Lithuania','Luxembourg','Madagascar, Rep. of','Malawi','Malaysia','Maldives','Mali','Malta','Marshall Islands, Rep. of the','Mauritania, Islamic Rep. of','Mauritius','Mexico','Moldova, Rep. of','Mongolia','Montenegro','Montserrat', 'Morocco','Mozambique, Rep. of','Myanmar','Namibia','Nauru, Rep. of','Nepal','Netherlands, The','New Caledonia','New Zealand','Nicaragua','Niger','Nigeria','North Macedonia, Republic of','Norway','Oman','Pakistan','Palau, Rep. of','Panama','Papua New Guinea','Paraguay','Peru','Philippines','Poland, Rep. of','Portugal','Qatar','Romania','Russian Federation','Rwanda','Samoa','São Tomé and Príncipe, Dem. Rep. of'))
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(echo = TRUE)
# Load the dataFrame
bops_data <- read.csv("/Users/sai_avinash/Documents/GitHub/Team_ASAB/BOPS.csv")
# Print the structure of the data base
str(bops_data)
# Get the column names
column_names <- colnames(bops_data)
column_names
# Change the column names
colnames(bops_data) <- c("Index", "Country", "CountryCode", "Indicator", "IndicatorCode", "2015", "2016", "2017", "2018", "2019", "2020")
# Verify the change
colnames(bops_data)
# check the head
head(bops_data, 20)
# Check the tail
tail(bops_data, 10)
# Change the Index column to  auto-increment type
bops_data$Index <- seq_len(nrow(bops_data))
# Check for the change
head(bops_data, 50)
tail(bops_data, 50)
# Structure of the data set
str(bops_data)
# Summary of the data set
summary(bops_data)
# Change the data types
bops_data$CountryCode <- as.factor(bops_data$CountryCode)
# Years to be changed as numeric
years_columns <- c("2015", "2016", "2017", "2018", "2019", "2020")
bops_data[years_columns] <- lapply(bops_data[years_columns], as.numeric)
# Store the
# Check the summary
summary_result <- summary(bops_data$CountryCode)
summary_result
# write.table(summary_result, "/Users/sai_avinash/Desktop/Output.txt", quote = FALSE, row.names = TRUE)
# Check the structure
#str(bops_data)
knitr::opts_chunk$set(echo = TRUE)
# Load the dataFrame
bops_data <- read.csv("/Users/sai_avinash/Documents/GitHub/Team_ASAB/BOPS.csv")
# Print the structure of the data base
str(bops_data)
# Load the dataFrame
bops_data <- read.csv("/Users/sai_avinash/Documents/GitHub/Team_ASAB/BOPS.csv")
# Print the structure of the data base
str(bops_data)
# Change the column names
colnames(bops_data) <- c("Index", "Country", "CountryCode", "Indicator", "IndicatorCode", "2015", "2016", "2017", "2018", "2019", "2020")
# Verify the change
colnames(bops_data)
# check the head
head(bops_data, 20)
# Check the tail
tail(bops_data, 10)
# Change the Index column to  auto-increment type
bops_data$Index <- seq_len(nrow(bops_data))
# Check for the change
head(bops_data, 50)
tail(bops_data, 50)
# Change the column names
colnames(bops_data) <- c("Index", "Country", "CountryCode", "Indicator", "IndicatorCode", "2015", "2016", "2017", "2018", "2019", "2020")
# Verify the change
colnames(bops_data)
# check the head
head(bops_data, 20)
# Check the tail
tail(bops_data, 10)
# Change the column names
colnames(bops_data) <- c("Index", "Country", "CountryCode", "Indicator", "IndicatorCode", "2015", "2016", "2017", "2018", "2019", "2020")
# Verify the change
colnames(bops_data)
# check the head
head(bops_data, 20)
# Check the tail
tail(bops_data, 10)
# Change the data types
bops_data$CountryCode <- as.factor(bops_data$CountryCode)
# Years to be changed as numeric
years_columns <- c("2015", "2016", "2017", "2018", "2019", "2020")
bops_data[years_columns] <- lapply(bops_data[years_columns], as.numeric)
# Store the
# Check the summary
summary_result <- summary(bops_data$CountryCode)
summary_result
# write.table(summary_result, "/Users/sai_avinash/Desktop/Output.txt", quote = FALSE, row.names = TRUE)
# Check the structure
#str(bops_data)
str(bops_data)
library(dplyr)
# Get the top 50 unique countries
unique_50_countries <- unique(bops_data$Country)[1:50]
unique_50_countries
library(dplyr)
# Get the top 50 unique countries
unique_50_countries <- unique(bops_data$Country)[1:51]
unique_50_countries
library(dplyr)
# Get the top 50 unique countries
unique_50_countries <- unique(bops_data$Country)[1:51]
# Extract all rows corresponding to these 50 countries
first_50_countries <- bops_data %>%
filter(Country %in% unique_50_countries)
first_50_countries
library(dplyr)
# Get the top 50 unique countries
unique_50_countries <- unique(bops_data$Country)[1:51]
# Extract all rows corresponding to these 50 countries
first_50_countries <- bops_data %>%
filter(Country %in% unique_50_countries)
# Write the result to a text file
write.table(first_50_countries, file = "/Users/sai_avinash/Desktop/first_50_countries.txt", row.names = FALSE, sep = "\t")
#first_50_countries
# check the null values for each column
null_in_2015 <- sum(is.na(first_50_countries["2015"]))
# check the null values for each column
null_in_2015 <- sum(is.na(first_50_countries["2015"]))
null_in_2015
# check the null values for each column
null_in_2015 <- sum(is.na(first_50_countries["2015"]))
null_in_2016 <- sum(is.na(first_50_countries["2016"]))
null_in_2017 <- sum(is.na(first_50_countries["2017"]))
null_in_2018 <- sum(is.na(first_50_countries["2018"]))
null_in_2019 <- sum(is.na(first_50_countries["2019"]))
null_in_2020 <- sum(is.na(first_50_countries["2020"]))
null_in_2015
null_in_2016
null_in_2017
null_in_2018
null_in_2019
null_in_2020
# check the null values for each column
null_in_2015 <- sum(is.na(first_50_countries["2015"]))
null_in_2016 <- sum(is.na(first_50_countries["2016"]))
null_in_2017 <- sum(is.na(first_50_countries["2017"]))
null_in_2018 <- sum(is.na(first_50_countries["2018"]))
null_in_2019 <- sum(is.na(first_50_countries["2019"]))
null_in_2020 <- sum(is.na(first_50_countries["2020"]))
# Count of rows with at least one missing value
num_rows_with_na <- sum(apply(first_50_countries, 1, function(row) any(is.na(row))))
print(num_rows_with_na)
null_in_2015
null_in_2016
null_in_2017
null_in_2018
null_in_2019
null_in_2020
# check the null values for each column
null_in_2015 <- sum(is.na(first_50_countries["2015"]))
null_in_2016 <- sum(is.na(first_50_countries["2016"]))
null_in_2017 <- sum(is.na(first_50_countries["2017"]))
null_in_2018 <- sum(is.na(first_50_countries["2018"]))
null_in_2019 <- sum(is.na(first_50_countries["2019"]))
null_in_2020 <- sum(is.na(first_50_countries["2020"]))
# Count of rows with at least one missing value
num_rows_with_na <- sum(apply(first_50_countries, 1, function(row) any(is.na(row))))
#print(num_rows_with_na)
# Remove the rows with null values
# Filter rows without any missing values
first_50_countries_cleaned <- first_50_countries[complete.cases(first_50_countries), ]
num_rows_with_na_cleaned <- sum(apply(first_50_countries_cleaned, 1, function(row) any(is.na(row))))
null_in_2015
null_in_2016
null_in_2017
null_in_2018
null_in_2019
null_in_2020
# check the null values for each column
null_in_2015 <- sum(is.na(first_50_countries["2015"]))
null_in_2016 <- sum(is.na(first_50_countries["2016"]))
null_in_2017 <- sum(is.na(first_50_countries["2017"]))
null_in_2018 <- sum(is.na(first_50_countries["2018"]))
null_in_2019 <- sum(is.na(first_50_countries["2019"]))
null_in_2020 <- sum(is.na(first_50_countries["2020"]))
# Count of rows with at least one missing value
num_rows_with_na <- sum(apply(first_50_countries, 1, function(row) any(is.na(row))))
#print(num_rows_with_na)
# Remove the rows with null values
# Filter rows without any missing values
first_50_countries_cleaned <- first_50_countries[complete.cases(first_50_countries), ]
num_rows_with_na_cleaned <- sum(apply(first_50_countries_cleaned, 1, function(row) any(is.na(row))))
num_rows_with_na_cleaned
null_in_2015
null_in_2016
null_in_2017
null_in_2018
null_in_2019
null_in_2020
# check the null values for each column
null_in_2015 <- sum(is.na(first_50_countries["2015"]))
null_in_2016 <- sum(is.na(first_50_countries["2016"]))
null_in_2017 <- sum(is.na(first_50_countries["2017"]))
null_in_2018 <- sum(is.na(first_50_countries["2018"]))
null_in_2019 <- sum(is.na(first_50_countries["2019"]))
null_in_2020 <- sum(is.na(first_50_countries["2020"]))
# Count of rows with at least one missing value
num_rows_with_na <- sum(apply(first_50_countries, 1, function(row) any(is.na(row))))
#print(num_rows_with_na)
# Remove the rows with null values
# Filter rows without any missing values
first_50_countries_cleaned <- first_50_countries[complete.cases(first_50_countries), ]
num_rows_with_na_cleaned <- sum(apply(first_50_countries_cleaned, 1, function(row) any(is.na(row))))
num_rows_with_na_cleaned
null_in_2015_c <- sum(is.na(first_50_countries["2015"]))
null_in_2016_c <- sum(is.na(first_50_countries["2016"]))
null_in_2017_c <- sum(is.na(first_50_countries["2017"]))
null_in_2018_c <- sum(is.na(first_50_countries["2018"]))
null_in_2019_c <- sum(is.na(first_50_countries["2019"]))
null_in_2020_c <- sum(is.na(first_50_countries["2020"]))
null_in_2015_c
null_in_2016_c
null_in_2017_c
null_in_2018_c
null_in_2019_c
null_in_2020_c
# check the null values for each column
null_in_2015 <- sum(is.na(first_50_countries["2015"]))
null_in_2016 <- sum(is.na(first_50_countries["2016"]))
null_in_2017 <- sum(is.na(first_50_countries["2017"]))
null_in_2018 <- sum(is.na(first_50_countries["2018"]))
null_in_2019 <- sum(is.na(first_50_countries["2019"]))
null_in_2020 <- sum(is.na(first_50_countries["2020"]))
# Count of rows with at least one missing value
num_rows_with_na <- sum(apply(first_50_countries, 1, function(row) any(is.na(row))))
#print(num_rows_with_na)
# Remove the rows with null values
# Filter rows without any missing values
first_50_countries_cleaned <- first_50_countries[complete.cases(first_50_countries), ]
num_rows_with_na_cleaned <- sum(apply(first_50_countries_cleaned, 1, function(row) any(is.na(row))))
num_rows_with_na_cleaned
null_in_2015_c <- sum(is.na(first_50_countries_cleaned["2015"]))
null_in_2016_c <- sum(is.na(first_50_countries_cleaned["2016"]))
null_in_2017_c <- sum(is.na(first_50_countries_cleaned["2017"]))
null_in_2018_c <- sum(is.na(first_50_countries_cleaned["2018"]))
null_in_2019_c <- sum(is.na(first_50_countries_cleaned["2019"]))
null_in_2020_c <- sum(is.na(first_50_countries_cleaned["2020"]))
null_in_2015_c
null_in_2016_c
null_in_2017_c
null_in_2018_c
null_in_2019_c
null_in_2020_c
# filter the data
library(dplyr)
# Drop rows of countries with fewer than 20 indicators
filtered_data <- first_50_countries_cleaned %>%
group_by(Country) %>%
filter(n() >= 20) %>%
ungroup()
nrow(filtered_data)
# check the null values for each column
null_in_2015 <- sum(is.na(first_50_countries["2015"]))
null_in_2016 <- sum(is.na(first_50_countries["2016"]))
null_in_2017 <- sum(is.na(first_50_countries["2017"]))
null_in_2018 <- sum(is.na(first_50_countries["2018"]))
null_in_2019 <- sum(is.na(first_50_countries["2019"]))
null_in_2020 <- sum(is.na(first_50_countries["2020"]))
# Count of rows with at least one missing value
num_rows_with_na <- sum(apply(first_50_countries, 1, function(row) any(is.na(row))))
#print(num_rows_with_na)
# Remove the rows with null values
# Filter rows without any missing values
first_50_countries_cleaned <- first_50_countries[complete.cases(first_50_countries), ]
num_rows_with_na_cleaned <- sum(apply(first_50_countries_cleaned, 1, function(row) any(is.na(row))))
num_rows_with_na_cleaned
# Check null values in the cleaned data set.
null_in_2015_c <- sum(is.na(first_50_countries_cleaned["2015"]))
null_in_2016_c <- sum(is.na(first_50_countries_cleaned["2016"]))
null_in_2017_c <- sum(is.na(first_50_countries_cleaned["2017"]))
null_in_2018_c <- sum(is.na(first_50_countries_cleaned["2018"]))
null_in_2019_c <- sum(is.na(first_50_countries_cleaned["2019"]))
null_in_2020_c <- sum(is.na(first_50_countries_cleaned["2020"]))
null_in_2015_c
null_in_2016_c
null_in_2017_c
null_in_2018_c
null_in_2019_c
null_in_2020_c
nrow(first_50_countries) # with null values and all the indicators
nrow(first_50_countries_cleaned) # after removing the null values
nrow(filtered_data) # after excluding the indicators less than 20
knitr::opts_chunk$set(echo = TRUE)
# Load the dataFrame
bops_data <- read.csv("BOPS.csv")
# Print the structure of the data base
str(bops_data)
# Get the column names
column_names <- colnames(bops_data)
column_names
# Change the column names
colnames(bops_data) <- c("Index", "Country", "CountryCode", "Indicator", "IndicatorCode", "2015", "2016", "2017", "2018", "2019", "2020")
# Verify the change
colnames(bops_data)
# check the head
head(bops_data, 20)
# Check the tail
tail(bops_data, 10)
# Change the Index column to  auto-increment type
bops_data$Index <- seq_len(nrow(bops_data))
# Check for the change
head(bops_data, 50)
tail(bops_data, 50)
# Number of rows and columns of this dataframe
number_rows <- nrow(bops_data)
number_columns <- length(bops_data)
number_rows
number_columns
# Structure of the data set
str(bops_data)
# Summary of the data set
summary(bops_data)
# Change the data types
bops_data$CountryCode <- as.factor(bops_data$CountryCode)
# Years to be changed as numeric
years_columns <- c("2015", "2016", "2017", "2018", "2019", "2020")
bops_data[years_columns] <- lapply(bops_data[years_columns], as.numeric)
# Check the summary
summary_result <- summary(bops_data$CountryCode)
summary_result
#write.table(summary_result, "Output.txt", quote = FALSE, row.names = TRUE)
# Check the structure
str(bops_data)
library(dplyr)
# Get the top 50 unique countries
unique_50_countries <- unique(bops_data$Country)[1:51]
# Extract all rows corresponding to these 50 countries
first_50_countries <- bops_data %>%
filter(Country %in% unique_50_countries)
# Write the result to a text file
#write.table(first_50_countries, file = "first_50_countries_uncleaned.csv", row.names = FALSE, sep = "\t")
#first_50_countries
# check the null values for each column
null_in_2015 <- sum(is.na(first_50_countries["2015"]))
null_in_2016 <- sum(is.na(first_50_countries["2016"]))
null_in_2017 <- sum(is.na(first_50_countries["2017"]))
null_in_2018 <- sum(is.na(first_50_countries["2018"]))
null_in_2019 <- sum(is.na(first_50_countries["2019"]))
null_in_2020 <- sum(is.na(first_50_countries["2020"]))
# Count of rows with at least one missing value
num_rows_with_na <- sum(apply(first_50_countries, 1, function(row) any(is.na(row))))
#print(num_rows_with_na)
# Remove the rows with null values
# Filter rows without any missing values
first_50_countries_cleaned <- first_50_countries[complete.cases(first_50_countries), ]
num_rows_with_na_cleaned <- sum(apply(first_50_countries_cleaned, 1, function(row) any(is.na(row))))
num_rows_with_na_cleaned
# Check null values in the cleaned data set.
null_in_2015_c <- sum(is.na(first_50_countries_cleaned["2015"]))
null_in_2016_c <- sum(is.na(first_50_countries_cleaned["2016"]))
null_in_2017_c <- sum(is.na(first_50_countries_cleaned["2017"]))
null_in_2018_c <- sum(is.na(first_50_countries_cleaned["2018"]))
null_in_2019_c <- sum(is.na(first_50_countries_cleaned["2019"]))
null_in_2020_c <- sum(is.na(first_50_countries_cleaned["2020"]))
null_in_2015_c
null_in_2016_c
null_in_2017_c
null_in_2018_c
null_in_2019_c
null_in_2020_c
# filter the data
# Drop rows of countries with fewer than 20 indicators
filtered_data <- first_50_countries_cleaned %>%
group_by(Country) %>%
filter(n() >= 20) %>%
ungroup()
# cleaned data
write.table(filtered_data, file = "first_50_countries_cleaned.csv", row.names = FALSE, sep = "\t")
knitr::opts_chunk$set(echo = TRUE)
str(first_50_countries)
indicators <- unique(first_50_countries$Indicator)
print(indicators)
indicators_aruba <- subset(first_50_countries_cleaned, indicators == "Aruba, Kingdom of the Netherlands")
indicators_aruba <- subset(first_50_countries_cleaned, Indicator == "Aruba, Kingdom of the Netherlands")
indicators_aruba$Indicator
nrow(indicators_aruba)
indicators_aruba <- subset(first_50_countries_cleaned, Indicator = "Aruba, Kingdom of the Netherlands")
indicators_aruba$Indicator
nrow(indicators_aruba)
indicators_aruba <- filter(first_50_countries_cleaned, Indicator = "Aruba, Kingdom of the Netherlands")
indicators_aruba <- subset(first_50_countries_cleaned, subset = (Indicator == "Aruba, Kingdom of the Netherlands"))
indicators_aruba$Indicator
nrow(indicators_aruba)
indicators_aruba <- subset(first_50_countries_cleaned, subset = (Indicator == "Aruba, Kingdom of the Netherlands"))
indicators_aruba$Indicator
nrow(indicators_aruba)s
knitr::opts_chunk$set(echo = TRUE)
# Read the cleaned final csv file
bops_data <- read.csv("BalanceOfPayment.csv")
# Read the cleaned final csv file
bops_data <- read.csv("BalanceOfPayment.csv")
# Summary of the data set
summary(bops_data)
