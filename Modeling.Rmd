---
title: "Modeling"
author: "Sai Avinash"
date: "`r Sys.Date()`"
output:
  html_document:
    code_folding: hide
    number_sections: false
    toc: yes
    toc_depth: 3
    toc_float: yes
  pdf_document:
    toc: yes
    toc_depth: '3'
---

```{r init, include=F}
# The package "ezids" (EZ Intro to Data Science) includes some helper functions we developed for the course. 
# Some of the frequently used functions are loadPkg(), xkabledply(), xkablesummary(), uzscale(), etc.
# You will need to install it (once) from GitHub.
# library(devtools)
# devtools::install_github("physicsland/ezids")
# Then load the package in your R session.
library(ezids)
```

```{r setup, include=FALSE}
# Some of common RMD options (and the defaults) are: 
# include=T, eval=T, echo=T, results='hide'/'asis'/'markup',..., collapse=F, warning=T, message=T, error=T, cache=T, fig.width=6, fig.height=4, fig.dim=c(6,4) #inches, fig.align='left'/'center','right', 
knitr::opts_chunk$set(warning = F, message = F)
# Can globally set option for number display format.
options(scientific=T, digits = 3) 
# options(scipen=9, digits = 3) 
```

```{r}
# 1. Do not provide answers/comments inside code blocks (like here) -- those are notes between coders/self and will be ignored for grading. 
# 2. Make sure your knitr options are set to include all results/code to be graded in the final document.
# 3. All charts/graphs/tables should have appropriate titles/labels/captions. 
# 4. Compose your answers using inline R code instead of using the code-block output as much as you can. 
# 5. Your grade is also determined by the style. Even if you answer everything correctly, but the .html does not look appealing, you will not get full credit. Pay attention to the details that we mentioned in class/homework and in previous sample .Rmd files. For example, how to use #, ##, ###, ..., bold face, italics, inline codes, tables, ..., {results = "asis"}, use of colors in plots/ggplots, and so forth.
```

```{r}
df <- read.csv('BalanceOfPayment.csv', header = TRUE)
```

```{r}
head(df, 15)
```

```{r}
# Rename the Indicators for better Interpretability, and conciseness
# Load the dplyr package
library(dplyr)

# Assuming your dataframe is named 'data'
# Replace the specific value in the 'Indicator' column
#df <- df %>%
 # mutate(Indicator = ifelse(Indicator == 'Net Lending (+) / Net Borrowing (-) (Balance from Current and Capital Account), US Dollars',
 #                           'Net Financial Position',
 #                           Indicator))
```

```{r}
# Group by 'Indicator' and count unique 'Country' for each 'Indicator'
indicator_country_count <- df_filtered %>%
  group_by(Indicator) %>%
  summarise(UniqueCountries = n_distinct(Country))

# Find the total number of unique countries in the dataset
total_countries <- n_distinct(df_filtered$Country)

# Identify indicators that are common across all countries
common_indicators <- filter(indicator_country_count, UniqueCountries == total_countries)

# Display the common indicators
print(common_indicators)
nrow(common_indicators)
```


```{r}
# Load necessary library
library(dplyr)

# Assuming your dataframe is named 'data'
# Replace 'data' with the actual name of your dataframe

# Group by Indicator and count the number of unique countries for each
indicator_counts <- df %>%
  group_by(Indicator) %>%
  summarize(Count = n_distinct(Country))

# Get the number of unique countries in the dataset
total_countries <- n_distinct(df$Country)

# Filter indicators that are present in all countries
common_indicators <- filter(indicator_counts, Count == total_countries)

# View the list of common indicators
print(common_indicators$Indicator)
```

```{r}
# Load necessary library
library(dplyr)

# Filter the original dataset to include only common indicators
filtered_data <- dplyr::filter(df, Indicator %in% common_indicators$Indicator)

write.csv(filtered_data, "filtered_data.csv", row.names = FALSE)
```

```{r}
# Reset the row names to start from 1 and continue sequentially
row.names(filtered_data) <- NULL

write.csv(filtered_data, "filtered_data_updated_index.csv", row.names = FALSE)
```


```{r}
data <- read.csv('filtered_data.csv', header = TRUE)
```

```{r}
# Fill the 'X' column with a sequence starting from 1
data$X <- seq(from = 1, to = nrow(data))

head(data)
```

```{r}
data <- read.csv('filtered_data_1.csv', header = TRUE)
```

```{r}
# Load necessary library
library(dplyr)

# Read the dataset, assuming it's named 'data.csv' and located at '/mnt/data'
data <- read.csv('filtered_data_1.csv', stringsAsFactors = FALSE)

# Replace the long indicator names with shorter names
data <- data %>%
  mutate(Indicator = case_when(
    Indicator == "Net Lending (+) / Net Borrowing (-) (Balance from Current and Capital Account), US Dollars" ~ "Net_Lending_Borrowing_Balance",
    Indicator == "Current Account, Goods and Services, Credit, US Dollars" ~ "Current_Account_Credit",
    Indicator == "Current Account, Goods and Services, Debit, US Dollars" ~ "Current_Account_Debit",
    Indicator == "Financial Account, Other Investment, Loans, Net Incurrence of Liabilities, US Dollars" ~ "Financial_Loans_Net_Liabilities",
    Indicator == "Financial Account, Other Investment, Loans, US Dollars" ~ "Financial_Loans_Total",
    Indicator == "Current Account, Goods and Services, Services, Transport, Credit, US Dollars" ~ "Transport_Services_Credit",
    Indicator == "Current Account, Goods and Services, Services, Transport, Debit, US Dollars" ~ "Transport_Services_Debit",
    Indicator == "Supplementary Items, Reserve Assets (with Fund Record), US Dollars" ~ "Supplementary_Reserve_Assets",
    Indicator == "Supplementary Items, Total Current + Capital Account, US Dollars" ~ "Supplementary_Current_Capital",
    TRUE ~ Indicator # This will keep all other indicators unchanged
  ))

# Write the updated dataset to a new CSV file
write.csv(data, 'filtered_data_2.csv', row.names = FALSE)
```

```{r}
library(dplyr)
library(tidyr)

# Assuming your dataframe is named 'data'
# Replace 'data' with the actual name of your dataframe

# Define the mapping of old and new indicator names
indicator_mapping <- setNames(
  c("Net_Lending_Borrowing_Balance", "Current_Account_Credit", 
    "Current_Account_Debit", "Financial_Loans_Net_Liabilities", 
    "Financial_Loans_Total", "Transport_Services_Credit", 
    "Transport_Services_Debit", "Supplementary_Reserve_Assets", 
    "Supplementary_Current_Capital"),
  c("Net Lending (+) / Net Borrowing (-) (Balance from Current and Capital Account), US Dollars",
    "Current Account, Goods and Services, Credit, US Dollars",
    "Current Account, Goods and Services, Debit, US Dollars",
    "Financial Account, Other Investment, Loans, Net Incurrence of Liabilities, US Dollars",
    "Financial Account, Other Investment, Loans, US Dollars",
    "Current Account, Goods and Services, Services, Transport, Credit, US Dollars",
    "Current Account, Goods and Services, Services, Transport, Debit, US Dollars",
    "Supplementary Items, Reserve Assets (with Fund Record), US Dollars",
    "Supplementary Items, Total Current + Capital Account, US Dollars")
)

# Update the Indicator names
data$Indicator <- indicator_mapping[data$Indicator]

# Calculate the balances for each indicator and year
results <- data %>%
  pivot_longer(
    cols = starts_with("X"),
    names_prefix = "X",
    names_to = "Year",
    values_to = "Value"
  ) %>%
  group_by(Country, Year) %>%
  summarise(
    Current_Account_Balance = sum(Value[Indicator == "Current_Account_Credit"]) - 
                              sum(Value[Indicator == "Current_Account_Debit"]),
    Financial_Account_Loans_Balance = sum(Value[Indicator == "Financial_Loans_Net_Liabilities"]) + 
                                      sum(Value[Indicator == "Financial_Loans_Total"]),
    Transport_Services_Balance = sum(Value[Indicator == "Transport_Services_Credit"]) - 
                                 sum(Value[Indicator == "Transport_Services_Debit"]),
    Supplementary_Items_Balance = sum(Value[Indicator == "Supplementary_Reserve_Assets"]) + 
                                  sum(Value[Indicator == "Supplementary_Current_Capital"])
  ) %>%
  ungroup()

# Check the results
head(results)

```



```{r}
# Load the dplyr package
library(dplyr)


# Perform the aggregation
aggregated_data <- data %>%
  group_by(Country, Year) %>%
  mutate(
    # Calculate Current Account Balance
    Current_Account_Balance = `Current Account, Goods and Services, Credit, US Dollars` - 
                              `Current Account, Goods and Services, Debit, US Dollars`,
    
    # Calculate Financial Account Loans Balance
    Financial_Account_Loans_Balance = `Financial Account, Other Investment, Loans, Net Incurrence of Liabilities, US Dollars` + 
                                      `Financial Account, Other Investment, Loans, US Dollars`,
    
    # Calculate Transport Services Balance
    Transport_Services_Balance = `Current Account, Goods and Services, Services, Transport, Credit, US Dollars` - 
                                 `Current Account, Goods and Services, Services, Transport, Debit, US Dollars`,
    
    # Calculate Supplementary Items Balance
    Supplementary_Items_Balance = `Supplementary Items, Reserve Assets (with Fund Record), US Dollars` + 
                                  `Supplementary Items, Total Current + Capital Account, US Dollars`
  ) %>%
  ungroup()

# View the first few rows of the aggregated dataset
head(aggregated_data)

```

```{r}
# Load necessary library
library(dplyr)

# Assuming your dataframe is named 'data'
# Replace 'data' with the actual name of your dataframe

# Initialize an empty dataframe to store the results
results <- data.frame()

# List of years to loop through
years <- c("2015", "2016", "2017", "2018", "2019", "2020")

# Loop through each year
for (year in years) {
  # Calculate each balance for the current year
  year_data <- data %>%
    mutate(
      Current_Account_Balance = get(paste0("`Current Account, Goods and Services, Credit, US Dollars_", year)) - 
                                get(paste0("`Current Account, Goods and Services, Debit, US Dollars_", year)),
      Financial_Account_Loans_Balance = get(paste0("`Financial Account, Other Investment, Loans, Net Incurrence of Liabilities, US Dollars_", year)) + 
                                        get(paste0("`Financial Account, Other Investment, Loans, US Dollars_", year)),
      Transport_Services_Balance = get(paste0("`Current Account, Goods and Services, Services, Transport, Credit, US Dollars_", year)) - 
                                   get(paste0("`Current Account, Goods and Services, Services, Transport, Debit, US Dollars_", year)),
      Supplementary_Items_Balance = get(paste0("`Supplementary Items, Reserve Assets (with Fund Record), US Dollars_", year)) + 
                                    get(paste0("`Supplementary Items, Total Current + Capital Account, US Dollars_", year))
    ) %>%
    select(Country, everything())

  # Add the year to the data
  year_data$Year <- year
  
  # Combine with the results
  results <- rbind(results, year_data)
}

# View the first few rows of the results
head(results)

```



```{r}

library(dplyr)
library(fastDummies)
library(tidyr)

# Load your data - replace with the actual path to your CSV file
train_data <- read.csv('/Users/sai_avinash/Documents/GitHub/Team_ASAB/Group 7 Summary Paper/TrainDataBops.csv', stringsAsFactors = FALSE)

# Generate dummy variables for the 'Country' column
train_data <- train_data %>%
  dummy_cols("Country", remove_selected_columns = TRUE)

# Standardize the continuous variables
continuous_vars <- c("CURRENT_ACCOUNT_NET", "FINANCIAL_LOANS", "Net_Lending_Borrowing_Balance", "SUPPLEMENTARY_NET", "TRANSPORT_SERVICES_NET")

train_data[continuous_vars] <- scale(train_data[continuous_vars])

# View the first few rows of the processed data
head(train_data)
```

```{r}
###### Test data

# Load your data - replace with the actual path to your CSV file
test_data <- read.csv('/Users/sai_avinash/Documents/GitHub/Team_ASAB/Group 7 Summary Paper/TestDataBops.csv', stringsAsFactors = FALSE)

# Generate dummy variables for the 'Country' column
test_data <- test_data %>%
  dummy_cols("Country", remove_selected_columns = TRUE)

# Standardize the continuous variables
continuous_vars <- c("CURRENT_ACCOUNT_NET", "FINANCIAL_LOANS", "Net_Lending_Borrowing_Balance", "SUPPLEMENTARY_NET", "TRANSPORT_SERVICES_NET")

test_data[continuous_vars] <- scale(test_data[continuous_vars])

# View the first few rows of the processed data
head(test_data)
```


```{r}
library(dplyr)
library(fastDummies)
library(caret)

# Assuming 'Net_Lending_Borrowing_Balance' is the target variable
target_var <- 'Net_Lending_Borrowing_Balance'

# Preprocess the train dataset
train_data <- train_data %>%
  dummy_cols("Country", remove_selected_columns = TRUE) %>%
  mutate(across(where(is.numeric), scale))

# Preprocess the test dataset
test_data <- test_data %>%
  dummy_cols("Country", remove_selected_columns = TRUE) %>%
  mutate(across(where(is.numeric), scale))

# Ensure both datasets have the same dummy variables
all_vars <- union(names(train_data), names(test_data))
train_data[setdiff(all_vars, names(train_data))] <- 0
test_data[setdiff(all_vars, names(test_data))] <- 0

# Fit the model on the train dataset
model <- lm(reformulate(setdiff(names(train_data), target_var), target_var), data = train_data)

# Make predictions on the test dataset
predictions <- predict(model, newdata = test_data)

# Add predictions to the test dataset to calculate residuals
test_data$Predictions <- predictions

# Calculate residuals
test_data$Residuals <- with(test_data, get(target_var) - Predictions)

# Evaluate the model's performance
# Calculate RMSE (Root Mean Squared Error)
rmse <- sqrt(mean(test_data$Residuals^2))
print(paste("RMSE:", rmse))

# Calculate R-squared
r_squared <- cor(test_data[[target_var]], test_data$Predictions)^2
print(paste("R-squared:", r_squared))

```

```{r}
library(dplyr)
library(fastDummies)
library(caret)

# Load the training data
train_data_path <- '/Users/sai_avinash/Documents/GitHub/Team_ASAB/Group 7 Summary Paper/TrainDataBops.csv' 
train_data <- read.csv(train_data_path, stringsAsFactors = FALSE)

# Load the testing data
test_data_path <- '/Users/sai_avinash/Documents/GitHub/Team_ASAB/Group 7 Summary Paper/TestDataBops.csv' 
test_data <- read.csv(test_data_path, stringsAsFactors = FALSE)

# Combine train and test data to ensure consistent factor levels
combined_data <- bind_rows(train_data, test_data, .id = "dataset_id")

# Generate dummy variables for the 'Country' column
combined_data <- combined_data %>%
  dummy_cols("Country", remove_first_dummy = TRUE, remove_selected_columns = TRUE)

# Split combined data back into train and test sets
train_data_processed <- combined_data %>%
  filter(dataset_id == "1") %>%
  select(-dataset_id)

test_data_processed <- combined_data %>%
  filter(dataset_id == "2") %>%
  select(-dataset_id)

# Standardize the continuous variables
continuous_vars <- c("CURRENT_ACCOUNT_NET", "FINANCIAL_LOANS", "Net_Lending_Borrowing_Balance", "SUPPLEMENTARY_NET", "TRANSPORT_SERVICES_NET")

# Note: It's important to use the same scaling parameters from train_data to scale test_data
train_data_processed[continuous_vars] <- scale(train_data_processed[continuous_vars])
scaling_parameters <- attr(scale(train_data[continuous_vars]), "scaled:center")

test_data_processed[continuous_vars] <- scale(test_data_processed[continuous_vars], center = scaling_parameters, scale = FALSE)

# 'Net_Lending_Borrowing_Balance' is the target variable
target_var <- 'Net_Lending_Borrowing_Balance'

# Fit the model on the train dataset
model <- lm(reformulate(setdiff(names(train_data_processed), target_var), target_var), data = train_data_processed)

# Make predictions on the test dataset
test_data_processed$Predictions <- predict(model, newdata = test_data_processed)

# Calculate residuals
test_data_processed$Residuals <- with(test_data_processed, Net_Lending_Borrowing_Balance - Predictions)

# Evaluate the model's performance
# Calculate RMSE (Root Mean Squared Error)
rmse <- sqrt(mean(test_data_processed$Residuals^2))
print(paste("RMSE:", rmse))

# Calculate R-squared
r_squared <- cor(test_data_processed[[target_var]], test_data_processed$Predictions)^2
print(paste("R-squared:", r_squared))

# Output the test predictions and residuals
write.csv(test_data_processed, '/path/to/TestDataPredictions.csv', row.names = FALSE)

```

```{r}
library(dplyr)
library(fastDummies)
library(caret)

# Load the training data
train_data <- read.csv('/Users/sai_avinash/Documents/GitHub/Team_ASAB/Group 7 Summary Paper/TrainDataBops.csv', stringsAsFactors = FALSE)

# Load the testing data
test_data <- read.csv('/Users/sai_avinash/Documents/GitHub/Team_ASAB/Group 7 Summary Paper/TestDataBops.csv', stringsAsFactors = FALSE)

# Function to clean country names
clean_country_names <- function(country_name) {
  gsub(" ", "_", gsub("[^[:alnum:] ]", "", country_name))
}

# Clean up country names in both datasets
train_data$Country <- sapply(train_data$Country, clean_country_names)
test_data$Country <- sapply(test_data$Country, clean_country_names)

# Generate dummy variables for the 'Country' column
train_data <- dummy_cols(train_data, "Country", remove_first_dummy = TRUE, remove_selected_columns = TRUE)
test_data <- dummy_cols(test_data, "Country", remove_first_dummy = TRUE, remove_selected_columns = TRUE)

# Ensure both datasets have the same dummy variables
all_vars <- union(names(train_data), names(test_data))
train_data[setdiff(all_vars, names(train_data))] <- 0
test_data[setdiff(all_vars, names(test_data))] <- 0

# Standardize the continuous variables
continuous_vars <- c("CURRENT_ACCOUNT_NET", "FINANCIAL_LOANS", "Net_Lending_Borrowing_Balance", "SUPPLEMENTARY_NET", "TRANSPORT_SERVICES_NET")
train_data[continuous_vars] <- scale(train_data[continuous_vars])
test_data[continuous_vars] <- scale(test_data[continuous_vars])

# Fit the model on the train dataset
target_var <- 'Net_Lending_Borrowing_Balance'
model <- lm(reformulate(setdiff(names(train_data), target_var), target_var), data = train_data)

# Make predictions on the test dataset
test_data$Predictions <- predict(model, newdata = test_data)

# Calculate residuals
test_data$Residuals <- with(test_data, get(target_var) - Predictions)

# Evaluate the model's performance
# Calculate RMSE (Root Mean Squared Error)
rmse <- sqrt(mean(test_data$Residuals^2))
print(paste("RMSE:", rmse/100))

# Calculate R-squared
r_squared <- cor(test_data[[target_var]], test_data$Predictions)^2
print(paste("R-squared:", r_squared))

# Output the test predictions and residuals
#write.csv(test_data, '/Users/sai_avinash/Documents/GitHub/Team_ASAB/Group 7 Summary Paper/TestDataPredictions_1.csv', row.names = FALSE)

#summary(model)

```

```{r}
# Load necessary libraries
library(dplyr)
library(caret)

# Assuming 'train_data' and 'test_data' are already loaded, preprocessed, and contain no NA values

one_of_the_redundant_predictors <- Country
# Fit the linear regression model (with a reduced number of predictors if necessary)
model <- lm(Net_Lending_Borrowing_Balance ~ . - one_of_the_redundant_predictors, data = train_data)

# Obtain the summary of the model
summary_model <- summary(model)

# Print the model summary
print(summary_model)

# Predict on the test dataset
predictions <- predict(model, newdata = test_data)

# Evaluate the model's performance
# Calculate residuals
residuals <- test_data$Net_Lending_Borrowing_Balance - predictions

# Calculate RMSE
rmse <- sqrt(mean(residuals^2))
print(paste("RMSE:", rmse))

# Calculate R-squared
r_squared <- summary_model$r.squared
print(paste("R-squared:", r_squared))

```

```{r}
library(dplyr)
library(caret)

# Assuming 'train_data' and 'test_data' are already loaded and preprocessed

# Define the target variable
target_var <- 'Net_Lending_Borrowing_Balance'

# Fit the linear regression model without the 'Country' variable
model <- lm(reformulate(setdiff(names(train_data), c(target_var, 'Country')), target_var), data = train_data)

# Obtain the summary of the model
summary_model <- summary(model)

# Print the model summary
print(summary_model)

# Predict on the test dataset
predictions <- predict(model, newdata = test_data)

# Evaluate the model's performance
# Calculate residuals
residuals <- test_data[[target_var]] - predictions

# Calculate RMSE (Root Mean Squared Error)
rmse <- sqrt(mean(residuals^2))
print(paste("RMSE:", rmse))

# Calculate R-squared
r_squared <- summary_model$r.squared
print(paste("R-squared:", r_squared))

summary(model)
```


```{r}
library(dplyr)
library(rpart)

# Load the training data
train_data <- read.csv('/Users/sai_avinash/Documents/GitHub/Team_ASAB/Group 7 Summary Paper/TrainDataBops.csv', stringsAsFactors = FALSE)

# Load the testing data
test_data <- read.csv('/Users/sai_avinash/Documents/GitHub/Team_ASAB/Group 7 Summary Paper/TestDataBops.csv', stringsAsFactors = FALSE)

# Define the target variable
target_var <- 'Net_Lending_Borrowing_Balance'

# Standardize the continuous variables
continuous_vars <- c("CURRENT_ACCOUNT_NET", "FINANCIAL_LOANS", "SUPPLEMENTARY_NET", "TRANSPORT_SERVICES_NET")
train_data[continuous_vars] <- scale(train_data[continuous_vars])
test_data[continuous_vars] <- scale(test_data[continuous_vars])

# Fit a regression tree model excluding 'X' and 'Country'
exclude_columns <- c("X", grep("Country", names(train_data), value = TRUE))
model_formula <- reformulate(setdiff(names(train_data), c(target_var, exclude_columns)), target_var)
tree_model <- rpart(model_formula, data = train_data, method = "anova")

# Make predictions on the test dataset
test_data$Predictions <- predict(tree_model, newdata = test_data)

# Evaluate the model's performance
# Calculate residuals
test_data$Residuals <- with(test_data, get(target_var) - Predictions)

# Calculate RMSE (Root Mean Squared Error)
rmse <- sqrt(mean(test_data$Residuals^2))
print(paste("RMSE:", rmse))

# Plot the tree
plot(tree_model)
text(tree_model, use.n = TRUE)

# Print the summary of the tree model
summary(tree_model)


```


```{r}
library(dplyr)
library(rpart)
library(rpart.plot)

# Load the training data
train_data <- read.csv('/Users/sai_avinash/Documents/GitHub/Team_ASAB/Group 7 Summary Paper/TrainDataBops.csv', stringsAsFactors = FALSE)

# Load the testing data
test_data <- read.csv('/Users/sai_avinash/Documents/GitHub/Team_ASAB/Group 7 Summary Paper/TestDataBops.csv', stringsAsFactors = FALSE)

# Define the target variable
target_var <- 'Net_Lending_Borrowing_Balance'

# Standardize the continuous variables
continuous_vars <- c("CURRENT_ACCOUNT_NET", "FINANCIAL_LOANS", "SUPPLEMENTARY_NET", "TRANSPORT_SERVICES_NET")
train_data[continuous_vars] <- scale(train_data[continuous_vars])
test_data[continuous_vars] <- scale(test_data[continuous_vars])

# Fit a regression tree model excluding 'X' and 'Country' with a maximum depth of 3
exclude_columns <- c("X", grep("Country", names(train_data), value = TRUE))
model_formula <- reformulate(setdiff(names(train_data), c(target_var, exclude_columns)), target_var)
tree_model <- rpart(model_formula, data = train_data, method = "anova", control = rpart.control(maxdepth = 3))

# Make predictions on the test dataset
test_data$Predictions <- predict(tree_model, newdata = test_data)

# Evaluate the model's performance
# Calculate residuals
test_data$Residuals <- with(test_data, get(target_var) - Predictions)

# Calculate RMSE (Root Mean Squared Error)
rmse <- sqrt(mean(test_data$Residuals^2))
print(paste("RMSE:", rmse))

# Save the plot as an image
png(filename = "/Users/sai_avinash/Documents/GitHub/Team_ASAB/Group 7 Summary Paper/tree_plot.png", width = 1024, height = 768)
rpart.plot(tree_model)
dev.off()

# Print the summary of the tree model
summary(tree_model)

```

```{r}
library(dplyr)
library(rpart)
library(rpart.plot)

# Load the training and testing data
train_data <- read.csv('Users/sai_avinash/Documents/GitHub/Team_ASAB/Group_7_Summary Paper/TrainDataBops.csv', stringsAsFactors = FALSE)
test_data <- read.csv('/Users/sai_avinash/Documents/GitHub/Team_ASAB/Group_7_Summary Paper/TestDataBops.csv', stringsAsFactors = FALSE)

# Define the target variable
target_var <- 'Net_Lending_Borrowing_Balance'

# Standardize the continuous variables
continuous_vars <- c("CURRENT_ACCOUNT_NET", "FINANCIAL_LOANS", "SUPPLEMENTARY_NET", "TRANSPORT_SERVICES_NET")
train_data[continuous_vars] <- scale(train_data[continuous_vars])
test_data[continuous_vars] <- scale(test_data[continuous_vars])

# Exclude 'X' and 'Country' columns
exclude_columns <- c("X", grep("Country", names(train_data), value = TRUE))
model_formula <- reformulate(setdiff(names(train_data), c(target_var, exclude_columns)), target_var)

# Fit the regression tree model with a maximum depth of 3
tree_model <- rpart(model_formula, data = train_data, method = "anova", control = rpart.control(maxdepth = 3))

# Make predictions on the test dataset
test_data$Predictions <- predict(tree_model, newdata = test_data)

# Calculate RMSE
test_data$Residuals <- test_data[[target_var]] - test_data$Predictions
rmse <- sqrt(mean(test_data$Residuals^2))
print(paste("RMSE:", rmse))

# Save the plot as an image
png(filename = "/Users/sai_avinash/Documents/GitHub/Team_ASAB/Group 7 Summary Paper/tree_plot.png", width = 1024, height = 768)
rpart.plot(tree_model, type = 4, extra = 104)  # type=4 and extra=104 for detailed plots
dev.off()

# Print the summary of the tree model
summary(tree_model)

```

```{r}
```{r}
library(dplyr)
library(rpart)
library(rpart.plot)

# Load the training and testing data
train_data <- read.csv('Users/sai_avinash/Documents/GitHub/Team_ASAB/Group_7_Summary Paper/TrainDataBops.csv', stringsAsFactors = FALSE)
test_data <- read.csv('/Users/sai_avinash/Documents/GitHub/Team_ASAB/Group_7_Summary Paper/TestDataBops.csv', stringsAsFactors = FALSE)

# Define the target variable
target_var <- 'Net_Lending_Borrowing_Balance'

# Standardize the continuous variables
continuous_vars <- c("CURRENT_ACCOUNT_NET", "FINANCIAL_LOANS", "SUPPLEMENTARY_NET", "TRANSPORT_SERVICES_NET")
train_data[continuous_vars] <- scale(train_data[continuous_vars])
test_data[continuous_vars] <- scale(test_data[continuous_vars])

# Exclude 'X' and 'Country' columns
exclude_columns <- c("X", grep("Country", names(train_data), value = TRUE))
model_formula <- reformulate(setdiff(names(train_data), c(target_var, exclude_columns)), target_var)

# Fit the regression tree model with a maximum depth of 3
tree_model <- rpart(model_formula, data = train_data, method = "anova", control = rpart.control(maxdepth = 3))

# Make predictions on the test dataset
test_data$Predictions <- predict(tree_model, newdata = test_data)

# Calculate RMSE
test_data$Residuals <- test_data[[target_var]] - test_data$Predictions
rmse <- sqrt(mean(test_data$Residuals^2))
print(paste("RMSE:", rmse))

# Save the plot as an image
png(filename = "/Users/sai_avinash/Documents/GitHub/Team_ASAB/Group 7 Summary Paper/tree_plot.png", width = 1024, height = 768)
rpart.plot(tree_model, type = 4, extra = 104)  # type=4 and extra=104 for detailed plots
dev.off()

# Print the summary of the tree model
summary(tree_model)

```
```

```{r}
print(getwd()) 
```